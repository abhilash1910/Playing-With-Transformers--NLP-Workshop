## NLP-Workshop: Playing-With-Transformers

<img src="https://camo.githubusercontent.com/b9d050a07e52c7930206d37d72a229ab484cae1ace09bf0fe1c6cf9c7f5d4bc0/68747470733a2f2f68756767696e67666163652e636f2f66726f6e742f6173736574732f68756767696e67666163655f6c6f676f2e737667">


This repository is for the NLP workshop conducted by me with [ML India](https://www.townscript.com/e/projectbased-nlp-workshop-sentiment-analysis-031431) and has been downloaded from the
[Kaggle Source Kernel](https://www.kaggle.com/abhilash1910/nlp-workshop-playing-with-transformers). The following is the walkthrough of the contents:

- Basics of Neural Networks
- Creating a Baseline with Simplified LSTM variants and static embeddings
- Understanding Attention Mechanism
- Encoder Decoders
- Coupled Single Block Transformers with Attention
- Dual Block Transformer
- Understanding BERT, DistilBert, Roberta,Albert,GPT embeddings
- Creating GPU based Transformer Classifiers for the BERT and GPT family
- Evaluating the performance of different transformer embeddings
- QA modelling with Transformers
- NER with Transformers

<img src="https://miro.medium.com/max/688/1*zR61FG9RUd6ul4ecXA_euQ.jpeg">
